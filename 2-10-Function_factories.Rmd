```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
  cache = TRUE
)
```

# Function factories

## Prerequisites

For most of this chapter we stay mainly in base R only. Just in very few exercises, we make additional usage of the **rlang** and the **ggplot2** package:

```{r}
library(rlang)
library(ggplot2)
```

## Factory fundamentals

1. __<span style="color:red">Q</span>__: The definition of `force()` is simple:

    ```{r}
    force
    ```
    
   Why is it better to `force(x)` instead of just `x`?
    
   __<span style="color:green">A</span>__: To be clear: `force(x)` is just syntactic sugar for `x`. However, as stated in the first edition of the textbook:
    
   > using this function clearly indicates that you’re forcing evaluation, not that you’ve accidentally typed `x`.

2. __<span style="color:red">Q</span>__: Base R contains two function factories, `approxfun()` and `ecdf()`. 
    Read their documentation and experiment to figure out what the functions do and what they return.

   __<span style="color:green">A</span>__:
   
   - **`approxfun()`**: `approxfun()` basically takes a combination of 2-dimensional data points + some extra specifications as arguments and returns a stepwise linear or constant interpolation function (defined on the range of given x-values, by default).

   - **`ecdf()`**: `ecdf()` means empirical density function. For a numeric vector, ecdf() returns the appropriate density function (of class “ecdf”, which is inheriting from class “stepfun”). You can describe it’s behaviour in 2 steps. In the first part of it’s body, the (x,y) pairs for the nodes of the density function are calculated. In the second part these pairs are given to approxfun.

3. __<span style="color:red">Q</span>__: Create a function `pick()` that takes an index, `i`, as an argument and returns a function with an argument `x` that subsets `x` with `i`.

    ```{r, eval = FALSE}
    pick(1)(x)
    # should be equivalent to
    x[[1]]
    
    lapply(mtcars, pick(5))
    # should be equivalent to
    lapply(mtcars, function(x) x[[5]])
    ```

   __<span style="color:green">A</span>__:
   
    ```{r}
    pick <- function(i) {
      force(i)
    
      function(x) x[[i]]
    }
    
    x <- 1:3
    identical(x[[1]], pick(1)(x))
    identical(lapply(mtcars, pick(5)), lapply(mtcars, function(x) x[[5]]))
    ```

4. __<span style="color:red">Q</span>__: Create a function that creates functions that compute the i^th^ [central moment](http://en.wikipedia.org/wiki/Central_moment) of a numeric vector. You can test it by running the following code:

    ```{r, eval = FALSE}
    m1 <- moment(1)
    m2 <- moment(2)

    x <- runif(100)
    stopifnot(all.equal(m1(x), 0))
    stopifnot(all.equal(m2(x), var(x) * 99 / 100))
    ```

   __<span style="color:green">A</span>__: For a discrete formulation look under [http://www.r-tutor.com/elementary-statistics/numerical-measures/moment](http://www.r-tutor.com/elementary-statistics/numerical-measures/moment).
    
    ```{r}
    moment <- function(i){
      force(i)
    
      function(x) sum((x - mean(x)) ^ i) / length(x)
    }
    
    m1 <- moment(1)
    m2 <- moment(2)

    x <- runif(100)
    stopifnot(all.equal(m1(x), 0))
    stopifnot(all.equal(m2(x), var(x) * 99 / 100))
    ```

5. __<span style="color:red">Q</span>__: What happens if you don't use a closure? Make predictions, then verify with the code below.

    ```{r}
    i <- 0
    new_counter2 <- function() {
      i <<- i + 1
      i
    }
    ```

   __<span style="color:green">A</span>__: Our counts aren't reliable anymore, as they are stored within the global environment, where thy can be easily overwritten, deleted or interfere with other counters:
   
    ```{r, error = TRUE}
    new_counter2()
    new_counter2()
    
    i <- 0
    new_counter2()
    ```

6. __<span style="color:red">Q</span>__: What happens if you use `<-` instead of `<<-`? Make predictions, then verify with the code below.

    ```{r}
    new_counter3 <- function() {
      i <- 0
      function() {
        i <- i + 1
        i
      }
    }
    ```

   __<span style="color:green">A</span>__: The counter will always return 1.
   
   ```{r}
   new_counter_3 <- new_counter3()
   
   new_counter_3()
   new_counter_3()
   ```
   
    This happens as the counter always starts in a fresh execution environment, enclosed by the same enclosing environment, where `i` (in this case) remains 0.

## Graphical factories

1. __<span style="color:red">Q</span>__: Compare and contrast `ggplot2::label_bquote()` with `scales::number_format()`.

   __<span style="color:green">A</span>__:

## Statistical factories

1. __<span style="color:red">Q</span>__: In `boot_model()`, why don't I need to force the evaluation of `df` or `model`?

   __<span style="color:green">A</span>__: `boot_model()` returns
   
    ```{r}
    function() {
      fitted + sample(resid)
    }
    ```
    
   Neither `df` nor `model` appear in it. The relevant values, `fitted` and `resid`, are calculated (and so evaluated) in the enclosing environment within `boot_model`. 
    
2. __<span style="color:red">Q</span>__: Why might you formulate the Box-Cox transformation like this?

    ```{r}
    boxcox3 <- function(x) {
      function(lambda) {
        if (lambda == 0) {
          log(x)
        } else {
          (x ^ lambda - 1) / lambda
        }
      }  
    }
    ```

   __<span style="color:green">A</span>__:

3. __<span style="color:red">Q</span>__: Why don't you need to worry that `boot_permute()` stores a copy of the data inside the function that it generates?

   __<span style="color:green">A</span>__: Anything created in a manufactured function, like those returned by `boot_compute()`, gets created in the function's execution environment. As we've learned in the environments chapter, execution environments are ephemeral: once the function has completed, the environment will be garbage collected. As long as we don't return the execution environment and assign the referencing object any further, we don't have to worry about it. Therefore, we have to be careful in case we are explicitly returning the environment or another function, which carries the execution environment as its enclosing enviornment.

4. __<span style="color:red">Q</span>__: How much time does `ll_poisson2()` save compared to `ll_poisson1()`?
    Use `bench::mark()` to see how much faster the optimisation occurs.
    How does changing the length of `x` change the results?

   __<span style="color:green">A</span>__: Let us recall the definitions of `ll_poisson1()` and `ll_poisson2()` from the book:
   
    ```{r}
    ll_poisson1 <- function(x) {
      n <- length(x)
    
      function(lambda) {
        log(lambda) * sum(x) - n * lambda - sum(lfactorial(x))
      }
    }
    
    ll_poisson2 <- function(x) {
      n <- length(x)
      sum_x <- sum(x)
      c <- sum(lfactorial(x))
      
      function(lambda) {
        log(lambda) * sum_x - n * lambda - c
      }
    }
    ```
    
   Additionally, the test case from the book is
    
    ```{r}
    x1 <- c(41, 30, 31, 38, 29, 24, 30, 29, 31, 38)
    ```
    
   A first benchmark for this vector reveals a performance improvement of factor 2 for `ll_poisson2()` over `ll_poisson1()`
   
    ```{r}    
    bench::mark(llp1 = optimise(ll_poisson1(x1), c(0, 100), maximum = TRUE),
                llp2 = optimise(ll_poisson2(x1), c(0, 100), maximum = TRUE))
    ```
    
   Regarding differing lengths of `x1`, we expect even further performance improvements of `ll_poisson2()` compared to `ll_poisson1()`, as the redundant calculations within `ll_poisson1()`, become more expensive with growing length of `x1`. The following results imply that for a length of `x1` of 100000, `ll_poisson2()` is about 25 times as fast as `ll_poisson1()`:
   
    ```{r}
    results <- vector(mode = "list", length = 5L)
    
    for (i in 1:length(results)) {
      x_i_length <- 10L^i
      x_i <- rpois(x_i_length, 100L)
      
      results[[i]] <- bench::mark(
      llp1 = optimise(ll_poisson1(x_i), c(0, 100), maximum = TRUE),
      llp2 = optimise(ll_poisson2(x_i), c(0, 100), maximum = TRUE))
    }
    
    library(magrittr)
   
    do.call(rbind, results) %>% 
      dplyr::select(expression, `itr/sec`) %>% 
      dplyr::mutate(x_length = 10^rep(1:5, each = 2)) %>% 
      tidyr::spread(key = expression, value = `itr/sec`) %>% 
      dplyr::mutate(relative_iterations_per_second = llp2 / llp1) %>% 
      ggplot(aes(x = x_length, y = relative_iterations_per_second)) +
      geom_point()
    ```
 
1. __<span style="color:red">Q</span>__: Which of the following commands is equivalent to `with(x, f(z))`?

   (a) `x$f(x$z)`.
   (b) `f(x$z)`.
   (c) `x$f(z)`.
   (d) `f(z)`.
   (e) It depends.

   __<span style="color:green">A</span>__: e: It dependes. Typically b (`f(x$z)`) is equivalent. However, if `x` is the current environment, also d (`f(z)`) is equivalent.

2. __<span style="color:red">Q</span>__: Compare and contrast the effects of `env_bind()` vs. `attach()` for the following code.
   
    ```{r}
    funs <- list(
      mean = function(x) mean(x, na.rm = TRUE),
      sum = function(x) sum(x, na.rm = TRUE)
    )
    
    attach(funs)
    mean <- function(x) stop("Hi!")
    detach(funs)
    
    env_bind(globalenv(), !!!funs)
    mean <- function(x) stop("Hi!") 
    env_unbind(globalenv(), names(funs))
    ```

   __<span style="color:green">A</span>__:

## Old exercises

## Closures

1.  __<span style="color:red">Q</span>__: Why are functions created by other functions called closures?  

   __<span style="color:green">A</span>__: As stated in the book:

    > because they enclose the environment of the parent function and can access all its variables.

2.  __<span style="color:red">Q</span>__: What does the following statistical function do? What would be a better 
    name for it? (The existing name is a bit of a hint.)

    ```{r}
    bc <- function(lambda) {
      if (lambda == 0) {
        function(x) log(x)
      } else {
        function(x) (x ^ lambda - 1) / lambda
      }
    }
    ```  
    
    __<span style="color:green">A</span>__: It is the logarithm, when lambda equals zero and `x ^ lambda - 1 / lambda` otherwise. A better name might be `box_cox_transformation` (one parametric), you can read about it (here)[https://en.wikipedia.org/wiki/Power_transform].
    
3.  __<span style="color:red">Q</span>__: What does `approxfun()` do? What does it return?  
__<span style="color:green">A</span>__: `approxfun` basically takes a combination of 2-dimensional data points + some extra specifications as arguments and returns a stepwise linear or constant interpolation function (defined on the range of given x-values, by default).

4.  __<span style="color:red">Q</span>__: What does `ecdf()` do? What does it return?  
__<span style="color:green">A</span>__: "ecdf" means empirical density function. For a numeric vector, `ecdf()` returns the appropriate density function (of class "ecdf", which is inheriting from class "stepfun"). You can describe it's behaviour in 2 steps. In the first part of it's body, the `(x,y)` pairs for the nodes of the density function are calculated. In the second part these pairs are given to `approxfun`.

5.  __<span style="color:red">Q</span>__: Create a function that creates functions that compute the ith 
    [central moment](http://en.wikipedia.org/wiki/Central_moment) of a numeric 
    vector. You can test it by running the following code:

    ```{r, eval = FALSE}
    m1 <- moment(1)
    m2 <- moment(2)

    x <- runif(100)
    stopifnot(all.equal(m1(x), 0))
    stopifnot(all.equal(m2(x), var(x) * 99 / 100))
    ```  
    
    __<span style="color:green">A</span>__: For a discrete formulation look [here](http://www.r-tutor.com/elementary-statistics/numerical-measures/moment)
    
    ```{r, eval = FALSE}
    moment <- function(i){
      function(x) sum((x - mean(x)) ^ i) / length(x)
    }
    ```

6.  __<span style="color:red">Q</span>__: Create a function `pick()` that takes an index, `i`, as an argument and 
    returns a function with an argument `x` that subsets `x` with `i`.

    ```{r, eval = FALSE}
    lapply(mtcars, pick(5))
    # should do the same as this
    lapply(mtcars, function(x) x[[5]])
    ```  
    
    __<span style="color:green">A</span>__: 
    
    ```{r, eval = FALSE}
    pick <- function(i){
      function(x) x[[i]]
      }
    
    stopifnot(identical(lapply(mtcars, pick(5)),
                        lapply(mtcars, function(x) x[[5]]))
              )
    ```    

## Case study: numerical integration

1.  __<span style="color:red">Q</span>__: Instead of creating individual functions (e.g., `midpoint()`, 
      `trapezoid()`, `simpson()`, etc.), we could store them in a list. If we 
    did that, how would that change the code? Can you create the list of 
    functions from a list of coefficients for the Newton-Cotes formulae?  
    __<span style="color:green">A</span>__: 

2.  __<span style="color:red">Q</span>__: The trade-off between integration rules is that more complex rules are 
    slower to compute, but need fewer pieces. For `sin()` in the range 
    [0, $\pi$], determine the number of pieces needed so that each rule will 
    be equally accurate. Illustrate your results with a graph. How do they
    change for different functions? `sin(1 / x^2)` is particularly challenging.  
    __<span style="color:green">A</span>__: 
