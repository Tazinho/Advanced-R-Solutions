```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
  cache = TRUE
)

Sys.setenv(LANGUAGE = "en")
library("methods")
```
```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
  cache = TRUE
)

Sys.setenv(LANGUAGE = "en")
library("methods")
```
```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
  cache = TRUE
)

Sys.setenv(LANGUAGE = "en")
library("methods")
```

# Testchapter

# Names and values

## Binding basics

1.  __<span style="color:red">Q</span>__: Explain the relationship between `a`, `b`, `c` and `d` in the following code:

    ```{r}
    a <- 1:10
    b <- a
    c <- b
    d <- 1:10
    ```
    
    __<span style="color:green">A</span>__: `a`, `b`, `c` point to the same object (same address in memory) with the value `1:10`. So this object gets three name bindings. `d` points to another object with the same value.

1.  __<span style="color:red">Q</span>__: The following code accesses the mean function in multiple different ways. Do they all point to the same underlying function object? Verify with `lobstr::obj_addr()`.
    
    ```{r, eval = FALSE}
    mean
    base::mean
    get("mean")
    evalq(mean)
    match.fun("mean")
    ```
    
    __<span style="color:green">A</span>__: Yes, they point to the same object. To confirm that, we look at the address of the underlying function object. Since `lobstr::obj_addr()` currently returns an error, we use `pryr::address()` to inspect the addresses:
    
    ```{r}
    pryr::address(mean)
    
    x1 <- mean
    pryr::address(x1)
    
    x2 <- base::mean
    pryr::address(x2)
    
    x3 <- get("mean")
    pryr::address(x3)
    
    x4 <- evalq(mean)
    pryr::address(x4)
    
    x5 <- match.fun("mean")
    pryr::address(x5)
    ```
    
1.  __<span style="color:red">Q</span>__: By default, base R data import functions, like `read.csv()`, will automatically convert non-syntactic names to syntactic names. Why might this be problematic? What option allows you to suppress this behaviour?
    
    __<span style="color:green">A</span>__: This might be especially problematic in non-interactive R usage, when R reads and writes data and the output is expected to contain the same names as used in the data source. One can suppress the name conversion via setting the `check.names` argument to `FALSE`.
    
1.  __<span style="color:red">Q</span>__: What rules does `make.names()` use to convert non-syntactic names into syntactic names?
    
    __<span style="color:green">A</span>__: A valid name starts with a letter or a dot (which must not be followed by a number). It also consists only of letters, numbers, dots and underscores (`"_"` are allowed since R version 1.9.0). There are three main strategies applied to construct syntactically valid names (see also `?make.names`):
    
    * prepend an `X`: This strategy is applied d to names which don't start with a letter or start with a dot followed by a number:
    
    ```{r}
    make.names("")
    make.names(".1")
    ```
    
    * (additionally) non valid characters are replaced by a dot:
    
    ```{r}
    make.names("@")  # prepending + . replacement 
    make.names("  ")  # prepending + .. replacement
    make.names("non-valid")  # . replacement
    ```
    
    * reserved R keywords (see `?reserved`) get a dot appended:
    
    ```{r}
    make.names("if")
    ```
    
    Also mentioned in the help file:

    > The definition of a letter depends on the current locale, but only ASCII digits are considered to be digits.

1.  __<span style="color:red">Q</span>__: I slightly simplified the rules that govern syntactic names. Why is `.123e1` not a syntactic name? Read `?make.names`.
    
    __<span style="color:green">A</span>__: It is not syntactically valid as it starts with one dot which is followed by a number.

## Copy-on-modify

1.  __<span style="color:red">Q</span>__: Why is `tracemem(1:10)` not useful?

    __<span style="color:green">A</span>__: Without a binding `1:10` will not stay in memory (there will be no reference) and it makes no sense to track an object for copies which doesn't exist. Also when we assign `1:10` to a name, it will be clear, that `1:10` will only be the value of the object created and there is no "general" object `1:10`, which one would wan't to track.

1.  __<span style="color:red">Q</span>__: Explain why `tracemem()` records two copies when you run this code. 
    Hint: carefully look at the difference between this code and the code show earlier in the section.
     
    ```{r, results = FALSE}
    x <- 1:3
    tracemem(x)
    
    x[[3]] <- 4
    ```
    
    __<span style="color:green">A</span>__: Initially `x` is an integer vector. Within the replacement call, we assign a double to the third element of `x`. So besides the new value of the third element also a type conversion (coercion) is triggered affecting whole vector:
    
    ```{r}
    # two copies
    x <- 1:3
    tracemem(x)
    
    x[[3]] <- 4
    
    # the same as 
    x <- 1:3
    tracemem(x)
    
    x <- 4L
    x <- as.double(x)
    
    # one copy
    x <- 1:3
    
    tracemem(x)
    x[[3]] <- 4L
    ```

1.  __<span style="color:red">Q</span>__: Sketch out the relationship between the following objects:

    ```{r}
    a <- 1:10
    b <- list(a, a)
    c <- list(b, a, 1:10)
    ```
    
    __<span style="color:green">A</span>__: `a` contains a reference to an address with the value `1:10`. `b` contains a list of the same reference as `a` (twice). `c` contains a list of `b`, `a` (both containing the same reference three times) and a reference pointing to a different address containing the same value (`1:10`).

1.  __<span style="color:red">Q</span>__: What happens when you run this code:

    ```{r}
    x <- list(1:10)
    x[[2]] <- x
    ```
    
    Draw a picture.

## Object size

1.  __<span style="color:red">Q</span>__: Take the following list. Why is its size somewhat misleading?

    ```{r, return = FALSE}
    x <- list(mean, sd, var)
    # obj_size(x)
    #> 16,928 B
    ```

1.  __<span style="color:red">Q</span>__: Predict the output of the following code:

    ```{r, eval = FALSE}
    # x <- 1:1e6
    # obj_size(x)
    # 
    # y <- list(x, x)
    # obj_size(y)
    # obj_size(x, y)
    # 
    # y[[1]][[1]] <- 10
    # obj_size(y)
    # obj_size(x, y)
    # 
    # y[[2]][[1]] <- 10
    # obj_size(y)
    # obj_size(x, y)
    ```
    
    __<span style="color:green">A</span>__: Since `lobstr::obj_size()` currently throws an error, we use `unclass(pryr::obj_size())` instead. 
    
    To predict the size of `x`, we first find out via `object_size(integer(0))` that an integer takes 40 B. For every element of the integer vector additionally 4 B are needed and R allocates memory in chunks of 2, so 8 B at a time. This can be verified for example via `sapply(1:100, function(x) pryr::object_size(integer(x)))`. Overall our prediction will result in 40 B + 1000000 * 4 B = 4000040 B:
    
    ```{r}
    x <- 1:1e6
    unclass(pryr::object_size(x))
    ```
    
    To predict the size of `y <- list(x, x)` we make usage of the fact that both list elements point to the same memory and hence are the same reference which means neither one needs additional memory. A list takes 40 B in memory and 8 B for each element (we can verify this in the same way as for integers). Overall our prediction will result in x (4000040 B) + list of length 2 (40 B + 16 B):
    
    ```{r}
    y <- list(x, x)
    unclass(pryr::object_size(y))
    ```
    
    Since `x` and `y` are names with bindings to objects that point to the same reference, no additional memory is needed and our prediction is the maximum memory of both objects (y; 4000040 B):
    
    ```{r}
    unclass(pryr::object_size(x, y))
    ```
    
    The next one gets a bit more tricky. Since the first element of `y` becomes different to `x`, a completely new object is created in memory. Hence 10 is of type double (which triggers a silent coercion), the new object will take more memory. A double needs 40 B + length * 8 B (overall 8000040 B). So we get: first element of `y` (8000040 B) + second element of `y` (`x`; 4000040 B) + list of length 2 (40 B + 16 B) = 12000136 B as our prediction:
    
    ```{r}
    y[[1]][[1]] <- 10
    unclass(pryr::object_size(y))
    ```
    
    Again all elements of `x` are shared within `y` (`x` is the second element of `y`). So the overall memory usage corresponds to `y`'s:
    
    ```{r}
    unclass(pryr::object_size(x, y))
    ```
    
    In the next example also the second element of `y` gets the same value as the first one. However, R does not now, that it is the same as the first element, so a new object is created taking the same amount of memory:
    
    ```{r}
    y[[2]][[1]] <- 10
    unclass(pryr::object_size(y))
    ```
    
    Now `x` and `y` don't share any values anymore (from Rs perspective) and their memory adds up:
    
    ```{r}
    unclass(pryr::object_size(x, y))
    ```

## Modify-in-place

1.  __<span style="color:red">Q</span>__: Wrap the two methods for subtracting medians into two functions, then use the microbenchmark to carefully compare their speeds. How does performance change as the number of columns increase?
    
    __<span style="color:green">A</span>__: We can write one function that handles data frames and lists:
    
    ```{r}
    subtract_medians <- function(x, med){
      for (i in seq_along(medians)) {
        x[[i]] <- x[[i]] - medians[[i]]
      }
      x
    }
    ```
    
    The grid we choose is relatively dense to highlight the progress in the plot below:
    
    ```{r}
    n_grid <- c(seq(from = 1   , to = 9   , by = 1),
                seq(from = 10  , to = 90  , by = 10),
                seq(from = 100 , to = 900 , by = 100),
                seq(from = 1000, to = 5000, by = 1000), 
                10000L)
    ```

    Let's do our benchmark:
    
    ```{r, cache = TRUE}
    benchmarks <- vector(mode = "list", length = length(n_grid))
    
    for (n in seq_along(n_grid)){
      
      x <- data.frame(matrix(runif(n_grid[n] * 1e4), ncol = n_grid[n]))
      xl <- as.list(x)
      
      medians <- vapply(x, median, numeric(1))
      
      benchmarks[[n]] <- microbenchmark::microbenchmark(
        subtract_medians(x , median),
        subtract_medians(xl, median),
        times = 50L, unit = "ms"
      )
    }
    
    benchmarks <- dplyr::bind_rows(lapply(benchmarks, function(x) summary(x)))
    benchmarks[["n"]] <- rep(n_grid, each = 2)
    ```
    
    And plot the results:
    
    ```{r}
    plot(median ~ n, data = benchmarks, col = expr,
         ylab = "median", xlab = "n")
    ```
    
    Overall the performance difference rises more than linear in the range from 1 to 10000 columns:
    
    ```{r}
    plot(n_grid,
         abs(diff(benchmarks[["median"]])[c(TRUE, FALSE)]),
         xlab = "n",
         ylab = "difference between list and data frame performance in ms")
    ```

1.  __<span style="color:red">Q</span>__: What happens if you attempt to use `tracemem()` on an environment?

# S3

## Basics

1.  __<span style="color:red">Q</span>__: The most important S3 objects in base R are factors, data frames, and date/times (Dates, POSIXct, POSIXlt). You've already seen the attributes and base type that factors are built on. What base types and attributes are the others built on?
    
    __<span style="color:green">A</span>__: 
    
    **data frame:** Data frames are build up on (named) lists. Together with the `row.names` attribute and after setting the class to "data.frame", we get a classical data frame
    
    ```{r}
    df_build <- structure(list(1:2, 3:4),
                          names = c("a", "b"),
                          row.names = 1:2, 
                          class = "data.frame")
    
    df_classic <- data.frame(a = 1:2, b = 3:4)
    
    identical(df_build, df_classic)
    ```
    
    **date/times (Dates, POSIXct, POSIXlt):** Date is just a double with the class attribute set to "Date"
    
    ```{r}
    date_build <- structure(0, class = "Date")
    date_classic <- as.Date("1970-01-01")
    identical(date_build, date_classic)
    ```
    
    POSIXct is a class for date/times that inherits from POSIXt and is built on doubles as well. The only attribute is tz (for timezone)
    
    ```{r}
    POSIXct_build <- structure(1, class = c("POSIXct", "POSIXt"), tzone = "CET")
    POSIXct_classic <- .POSIXct(1, tz = "CET") # note that tz's default is NULL
    identical(POSIXct_build, POSIXct_classic)
    ```
    
    POSIXlt is another date/time class that inherits from POSIXt. It is built on top of a named list and a tzone attribute. Differences between POSIXct and POSIXlt are described in `?DateTimeClasses`.
    
    ```{r}
    POSIXlt_build <- structure(list(sec = 30,
                                    min = 30L,
                                    hour = 14L,
                                    mday = 1L,
                                    mon = 0L,
                                    year = 70L,
                                    wday = 4L,
                                    yday = 0L,
                                    isdst = 0L,
                                    zone = "CET",
                                    gmtoff = 3600L),
                               tzone = c("", "CET", "CEST"),
                               class = c("POSIXlt", "POSIXt"))
    POSIXlt_classic <- as.POSIXlt(.POSIXct(13.5 * 3600 + 30))
    identical(POSIXlt_build, POSIXlt_classic)
    ```

1.  __<span style="color:red">Q</span>__: Describe the difference in behaviour in these two calls.

    ```{r}
    set.seed(1014)
    some_days <- as.Date("2017-01-31") + sample(10, 5)
    
    mean(some_days)
    mean(unclass(some_days))
    ```
    
    __<span style="color:green">A</span>__: Since `mean()` is a generic and `some_days` is an object of class Date, the first call results in `mean.Date(some_days)`.  
    
    In the second call `unclass()` removes the class attribute from `some_days`, which means that `unclass(some_days)` is not an OO object and the call results in `mean.default(unclass(some_days))`, which calculates the mean of the underlying double.  
    
    When you look into the source code of `mean.Date()` (one line), you will see that the difference in the resulting objects is only the class attribute.

1.  __<span style="color:red">Q</span>__: Draw a Venn diagram illustrating the relationships between functions, generics, and methods.
    
    __<span style="color:orange">A</span>__: Funtions don't have to be generics or methods, but both the latter are functions. It is also possible that a function is both, a method and a generic, at the same time, which seems to be relatively awkward, so that also the author of the textbook doesn't recommend it, see `?pryr::ftype`

    > This function figures out whether the input function is a regular/primitive/internal function, a internal/S3/S4 generic, or a S3/S4/RC method. This is function is slightly simplified as it's possible for a method from one class to be a generic for another class, but that seems like such a bad idea that hopefully no one has done it.

1.  __<span style="color:red">Q</span>__: What does the `as.data.frame.data.frame()` method do? Why is it confusing? How should you avoid this confusion in your own code?
    
    __<span style="color:green">A</span>__: The name is confusing, because it is not clear, from the name, if it is a normal function, a generic or a method. Even if we know, that it is a method, the name doesn't tell us, which part is the name of the generic and which part is the class name.  
We can easily avoid this confusion, by forgoing to use period separated class and function names.

    To reveal the solution: `as.data.frame.data.frame()` is the data frame method of the `as.data.frame()` generic. Methods of this generic generally coerce objects to data frames.  
    This specific method strips all class attributes preceding the "data.frame" class.  
    If row names are supplied, this method will check their length and then set these as new "row.names" attribute.

1.  __<span style="color:red">Q</span>__: What does the following code return? What base type is built on?
    What attributes does it use?
    
    ```{r}
    x <- ecdf(rpois(100, 10))
    x
    ```
    
    __<span style="color:green">A</span>__: It returns the Empirical Cumulative Distribution Function of `rpois(100, 10)`. It is built on the base type "closure" and it saves the expression, which was used to create it, in its `call` attribute.

## Classes

1.  __<span style="color:red">Q</span>__: Categorise the objects returned by `lm()`, `factor()`, `table()`, 
    `as.Date()`, `ecdf()`, `ordered()`, `I()` into "vector", "scalar", and 
    "other".
    
    __<span style="color:green">A</span>__: 
    
    vector: `factor()`, `table()`, `as.Date()`, `ordered()`  
    scalar: `lm()`  
    other: `ecdf()`, `I()`  

1.  __<span style="color:red">Q</span>__: Write a constructor for `difftime` objects. What base type are they built on? What attributes do they use? You'll need to consult the documentation, read some code, and perform some experiments.
    
    __<span style="color:green">A</span>__: Our constructor should be named `new_class_name`, have one argument for its base type and each attribute and check the base types of these arguments as well. 
    
    ```{r}
    new_difftime <- function(x, units = "auto") {
      stopifnot(is.double(x), is.character(units))
      
      structure(x, units = units, class = "difftime")
    }
    ```
    
    However, since the following result prints awkward
    
    ```{r}
    new_difftime(3)
    ```
    
    we get a little bit more "inspiration" by the original `difftime()` function and make the regarding changes. Basically we need to implement logic for the units attribute, in case it is set to `"auto"` and convert the value of the underlying double from seconds to the regarding unit, as commented in the following
    
    ```{r}
    new_difftime <- function(x, units = "auto") {
      stopifnot(is.double(x), is.character(units))
      
      # case units == "auto":
      if (units == "auto") 
        # when all time differences are NA, units should be "secs"
        units <- if (all(is.na(x))){
          "secs"
        } else {
          # otherwise set the units regarding to the minimal time difference
          x_min <- min(abs(x), na.rm = TRUE)
          if (!is.finite(x_min) || x_min < 60) {
            "secs"
          } else if (x_min < 3600){
            "mins"
          } else if (x_min < 86400){
            "hours"
          } else {
            "days"
          }
        }
      
      # we rescale the underlying double, according to the units
      x <- switch(units, 
                  secs = x,
                  mins = x/60,
                  hours = x/3600,
                  days = x/86400,
                  weeks = x/(7 * 86400))
      
      structure(x, units = units, class = "difftime")
    }
    
    # test
    new_difftime(c(NA, -3600, 86400))
    ```

1.  __<span style="color:red">Q</span>__: Write a constructor for `data.frame` objects. What base type is a data 
    frame built on? What attributes does it use? What are the restrictions 
    placed on the individual elements? What about the names?
    
    __<span style="color:green">A</span>__: Data frames are built on (named) lists and their only attribute is row.names. Row names must be unique and have the same length as observations within the data. They must be of type integer or character. Also all elements must have the same length. Technically there are no restrictions to column names apart to those of lists, so one could surround special names via backticks at creation (of course this is not recommended). A very good constructor regarding these criteria is already implemented within the S3 package.
    
    ```{r, comment = ""}
    S3::new_data.frame
    ```

1.  __<span style="color:red">Q</span>__: Enhance our `factor()` helper to have better behaviour when one or more `values` is not found in `levels`. What does `base::factor()` do in this situation?
    
    __<span style="color:green">A</span>__: `base::factor()` converts these values (silently) into `NA`'s. To improve our `factor()` helper, we write a more informative error message.
    
    ```{r, eval = FALSE}
    factor <- function(x, levels = unique(x)) {
      ind <- match(x, levels)
      
      # error when values occur, which are not in the levels
      if(any(is.na(ind))){
        stop("The following values do not occur in the levels: ",
             paste(setdiff(x,levels), collapse = ", "), ".", 
             call. = FALSE)
        }
      
      validate_factor(new_factor(ind, levels))
    }
    ```

1.  __<span style="color:red">Q</span>__: Carefully read the source code of `factor()`. What does it do that our constructor does not?
    
    __<span style="color:green">A</span>__: It allows more general values as `x` input and converts them to character or replaces them by `character(0)` (in case of `NULL`). It also ensures that the levels are unique. This is done by setting the levels via the `base::levels<-` function, which fails when one tries to supply duplicated level values.

1.  __<span style="color:red">Q</span>__: What would a constructor function for `lm` objects, `new_lm()`, look like?
    Why is a constructor function less useful for linear models?
    
    __<span style="color:orange">A</span>__: 
    
    ```{r}
    new_lm <- function(coefficiets, residuals, effects, rank, fitted.values, assign,
                       qr, df.residual, xlevels, call, terms, model) {
      
      stopifnot(is.double(coefficients), is.double(residuals), is.double(effects),
                is.integer(rank), is.double(fitted.values), is.integer(assign),
                is.list(qr), is.integer(df.residual), is.list(xlevels),
                is.language(call), is.language(terms), is.list(model))
      
      structure(
        list(
          coefficients = coefficients,
          residuals = residuals,
          effects = effects,
          rank = rank, 
          fitted.values = fitted.values,
          assign = assign,
          qr = qr,
          df.residual = df.residual,
          xlevels = xlevels,
          call = call,
          terms = terms, 
          model = model
          ),
        class = "lm"
      )
      }
    ```

## Generics and methods

1.  __<span style="color:red">Q</span>__: Read the source code for `t()` and `t.test()` and confirm that `t.test()` is an S3 generic and not an S3 method. What happens if you create an object with class `test` and call `t()` with it? Why?
    
    ```{r}
    x <- structure(1:10, class = "test")
    t(x)
    ```
    
    __<span style="color:green">A</span>__: We can see that `t.test()` is a generic, because it calls `UseMethod()`
    
    ```{r}
    t.test
    ```  
    
    There are also other (programmatic) possibilities to check this like `pryr::ftype()`, which checks via its internal `pryr:::is_s3_generic`, which uses `codetools::findGlobals()` that `t.test()` contains a call to `UseMethod()`.
    
    Interestingly, while digging a bit around in the pryr package, one can also find some dependencies to the tools package, where a list of functions exists, which tells you about some functions that look like methods, but are not.
    
    ```{r}
    tools::nonS3methods("stats")
    ```
    
    However, if we create an object with class `test`, `t()`, will dispatch to `t.test()`. This simply happens, because `UseMethod()` just looks for functions named `paste0("generic", ".", c(class(x), "default"))`. So `t.test()` is erroneously treated like a method of `t()`. Since `t.test()` is a generic itself and doesn't find a method called `t.test.test()`, it dispatches to `t.test.default()`. Just to proof the latter quickly, we specify a method `t.test.test()` and see what happens:
    
    ```{r}
    t.test.test <- function(x) t.default(x)
    t(x)
    ```

1.  __<span style="color:red">Q</span>__: Carefully read the documentation for `UseMethod()` and explain why the following code returns the results that it does. What two usual rules of function evaluation does `UseMethod()` violate?
    
    ```{r}
    g <- function(x) {
      x <- 10
      y <- 10
      UseMethod("g")
    }
    g.default <- function(x) c(x = x, y = y)
    
    x <- 1
    y <- 1
    g(x)
    ```
    
    __<span style="color:green">A</span>__: R looks for the `x` argument in `g()`'s calling environment (the global environment), where `x` is defined as 1. Then `g()` dispatches to `g.default()`. The `x` argument is given to `g.default()`. `y` is not defined inside it, so `g.default()` takes `y`'s value from the environment where `UseMethod()` created the call. There `y` is defined as 10.  
    
    `UseMethod()` behaves special in many ways, two of them are:
    
    * it never "returns" (any statement after `UseMethod` won't be evaluated)
    * the argument matching can become a bit tricky (generic and methods should have the same order of arguments or you must name them)
    
    ```{r}
    g <- function(x, y) {UseMethod("g")}
    g.default <- function(y, x) c(x = x, y = y)
    
    g(10, 100)
    g(x = 10, y = 100)
    ```

## Method dispatch

1.  __<span style="color:red">Q</span>__: Which base generic has the greatest number of defined methods?
    
    __<span style="color:green">A</span>__: `print()` has clearly the most
    
    ```{r}
    library(methods)
    objs <- mget(ls("package:base"), inherits = TRUE)
    funs <- Filter(is.function, objs)
    generics <- Filter(function(x) ("generic" %in% pryr::ftype(x)), funs)
    
    sort(
      lengths(sapply(names(generics), function(x) methods(x), USE.NAMES = TRUE)),
      decreasing = TRUE
      )[1:3]
    ```

1.  __<span style="color:red">Q</span>__: Explain what is happening in the following code.

    ```{r}
    generic2 <- function(x) UseMethod("generic2")
    generic2.a1 <- function(x) "a1"
    generic2.a2 <- function(x) "a2"
    generic2.b <- function(x) {
      class(x) <- "a1"
      NextMethod()
    }

    generic2(S3::new_s3_scalar(class = c("b", "a2")))
    ```
    
    __<span style="color:green">A</span>__: 
    
    * We supply an object of classes `b` and `a2` to `generic2()`, so R will look for a method`generic2.b()`
    * `generic2.b()` changes the class to `a1` and then calls `NextMethod()`
    * One could think, that R calls now`generic2.a1()`. But in fact, as mentioned
    in the textbook, `NextMethod()` 
    
        > doesn’t actually work with the class attribute of the object, but instead uses a special global variable (.Class) to keep track of which method to call next.

    * We can easily verify (for example via `print()`) that `.Class` is still `c("b", "a2")` and so `generic2.a2()` gets called.

## Inheritance

1.  __<span style="color:red">Q</span>__: The `ordered` class is a subclass of `factor`, but it's implemented in a very ad hoc way in base R. Implement it in a principled way by building a constructor and an `as_ordered` generic.
    
    ```{r}
    f1 <- factor("a", c("a", "b"))
    as.factor(f1)  
    as.ordered(f1) # loses levels
    ```

    __<span style="color:green">A</span>__: ordered is a subclass of factor, so we need to do the following
    
    * for factors: add a subclass argument to the constructor and helper
    * for ordered: add a constructor
    * write an `as_ordered()` generic with methods ordered, factor and default
    
    We use the **factor** constructor from the textbook and add the subclass argument
    
    ```{r}
    new_factor <- function(x, levels, ..., subclass = NULL) {
      stopifnot(is.integer(x))
      stopifnot(is.character(levels))
      
      structure(
        x,
        levels = levels,
        class = c(subclass, "factor")
      )
    }
    ```
    
    We also use the validator for factors from the textbook
    
    ```{r}
    validate_factor <- function(x) {
      values <- unclass(x)
      levels <- attr(x, "levels")
      
      if (!all(!is.na(values) & values > 0)) {
        stop(
          "All `x` values must be non-missing and greater than zero",
          call. = FALSE
        )
      }
      
      if (length(levels) < max(values)) {
        stop(
          "There must at least as many `levels` as possible values in `x`",
          call. = FALSE
        )
      }
      
      x
    }
    ```
    
    And we add the subclass argument for the helper from the textbook and the exercises
    
    ```{r}
    factor <- function(x, levels = unique(x), ... , subclass = NULL) {
      ind <- match(x, levels)
      
      # error when values occur, which are not in the levels
      if(any(is.na(ind))){
        stop("The following values do not occur in the levels: ",
             paste(setdiff(x,levels), collapse = ", "), ".", 
             call. = FALSE)
        }
      
      validate_factor(new_factor(ind, levels, subclass = subclass))
    }
    ```
    
    A constructor for ordered is already implemented in the S3 package:
    
    ```{r}
    new_ordered <- function (x, levels) {
      stopifnot(is.integer(x))
      stopifnot(is.character(levels))
      structure(x, levels = levels, class = c("ordered", "factor"))
    }
    ```
    
    The implementation of the **generic** and the first two methods is straight forward
    
    ```{r}
    as_ordered <- function(x, ...) {
      UseMethod("as_ordered")
    }
    
    as_ordered.ordered <- function(x, ...) x
    as_ordered.default <- function(x, ...) {
      stop(
        "Don't know how to coerce object of class ", 
        paste(class(x), collapse = "/"), " into an ordered factor", 
        call. = FALSE
      )
    }
    ```
    
    For the factor method of `as_ordered()` we use the factor helper, since it saves us some typing:
    
    ```{r}
    as_ordered.factor <- function(x, ...) {
      factor(x, attr(x, "levels"), subclass = "ordered")
    }
    ```
    
    Finally, our new method preserves all levels:
    
    ```{r}
    as_ordered(f1)
    ```
    
    For a real scenario, we might want to add an `as_factor.ordered()` method to the `as_factor()` generic from the textbook.
        
1.  __<span style="color:red">Q</span>__: What classes have a method for the `Math` group generic in base R? Read the source code. How do the methods work?

    __<span style="color:green">A</span>__: The following functions belong to this group (see ?`Math`):
    
    * abs, sign, sqrt, floor, ceiling, trunc, round, signif
    * exp, log, expm1, log1p, cos, sin, tan, cospi, sinpi, tanpi, acos, asin, atan, cosh, sinh, tanh, acosh, asinh, atanh
    * lgamma, gamma, digamma, trigamma
    * cumsum, cumprod, cummax, cummin
    
    The following classes have a method for this group generic:
    
    ```{r}
    methods("Math")
    ```
    
    To read the source code of the S3 classes, we can just enter the name of the method into the console. To get the source code of the S4 classes, we can use `getMethod()`, i. e. `getMethod("Math", "nonStructure")`.
    
    To explain the basic idea, we just overwrite the data frame method:
    
    ```{r}
    Math.data.frame <- function(x){"hello"}
    ```
    
    Now all functions from the math generic group, will return `"hello"`
    
    ```{r}
    abs(iris)
    exp(iris)
    lgamma(iris)
    ```
    
    So, I hope the idea is clear. However, of course different functions should perform different calculations. Here `.Generic` comes into play, which provides us the calling generic as a string

    ```{r}
    Math.data.frame <- function(x, ...){
      .Generic
    }
    
    abs(iris)
    exp(iris)
    lgamma(iris)
    
    rm(Math.data.frame)
    ```
    
    `Math.data.frame()` is a good example, how to invoke `.Generic` to build sth. constructive up on `.Generic`. `Math.factor()` is a good example of a method, which is simply defined for better error messages.

1.  __<span style="color:red">Q</span>__: R has two classes for representing date time data, `POSIXct` and `POSIXlt`, which both inherit from `POSIXt`. Which generics have different behaviours for the two classes? Which generics share the same behaviour?
    
    __<span style="color:green">A</span>__: To answer this question, we have to get the regarding generics
    
    ```{r}
    # generics of POSIXt
    generics_t <- attr(methods(class = "POSIXt"), "info")[["generic"]]
    # Generics of POSIXct
    generics_ct <- attr(methods(class = "POSIXct"), "info")[["generic"]]
    # generics of POSIXlt
    generics_lt <- attr(methods(class = "POSIXlt"), "info")[["generic"]]
    ```
    
    Those generics that have a method for POSIXt are potentially sharing the same behaviour (`generics_t`). However, those generics that have a specific method for one of the sublcases have to be subtractet:
    
    ```{r}
    generics_same <- setdiff(generics_t, union(generics_ct, generics_lt))
    generics_same
    ```
    
    The rest is different
    
    ```{r}
    generics_different <- union(generics_ct, generics_lt)
    generics_different
    ```

## Dispatch details

1.  __<span style="color:red">Q</span>__: `Math.difftime()` is more complicated than I described. Why?

    __<span style="color:green">A</span>__: `Math.difftime()` needs to exclude other cases than abs, sign, floor, ceiling, trunc, round and signif and supply an according error message.


# S4

## Classes

1.  __<span style="color:red">Q</span>__: What happens if you define a new S4 class that doesn't "contain" an existing class?  (Hint: read about virtual classes in `?setClass`.)
    
    __<span style="color:green">A</span>__: It depends on the other arguments.
    If we supply a class that doesn't exist, we'll get an error
    
    ```{r, error = TRUE}
    setClass("Programmer", slots = c(skill = "ANY"), contains = "Human")
    ```
    
    However, we can get around that, if we register the class before
    
    ```{r}
    setOldClass("Human")
    .Programmer <- setClass("Programmer", slots = c(Skill = "ANY"), contains = "Human")
    ```
    
    Supplying neither `slots`, nor `contains` results in a contructor for virtual classes 
    
    ```{r}
    .VirtualProgrammer <- setClass("VirtualProgrammer")
    # The same as contains = "VIRTUAL" (here you could also supply slots)
    .VirtualProgrammer <- setClass("VirtualProgrammer", contains = "VIRTUAL")
    ```
    
    Just leaving out `contains`, but supplying slots results in a constructor without superclass
    
    ```{r}
    .DataScientist <- setClass("RProgrammer", slots = c(stats = "ANY",
                                                        math = "ANY",
                                                        programming = "ANY"))
    ```

1.  __<span style="color:red">Q</span>__: Imagine you were going to reimplement ordered factors, dates, and data frames in S4. Sketch out the `setClass()` calls that you would use to define the classes. What should they inherit from? What slots should they use?

    __<span style="color:orange">A</span>__: The basic idea is to use a slot for the base type and one slot per attribute. Inheritance matters for ordered factors and dates. Special checks like equal lengths of list elements for columns of a data frame should be done within a validator.

## Generics and methods

1.  __<span style="color:red">Q</span>__: In the defintion of the generic, why is it necessary to repeat the name of the generic twice?

    __<span style="color:green">A</span>__: The first time it is needed as name of the generic and the second time it is needed to explicitly incorporate method dispacth via `standardGeneric()` within the generic's body (`def` parameter). This is similar to `UseMethod()` within S3.

1.  __<span style="color:red">Q</span>__: What's the difference between the generics generated by these two calls?
    
    ```{r, eval = FALSE}
    setGeneric("myGeneric", function(x) standardGeneric("myGeneric"))
    setGeneric("myGeneric", function(x) {
      standardGeneric("myGeneric")
    })
    ```
    
    __<span style="color:green">A</span>__: The first call defines a standard generic and the second one creates a nonstandard generic. One can confirm this directly whlie printing (showing in S4 jargon) the function.
    
    ```{r, eval = TRUE}
    setGeneric("myGeneric", function(x) standardGeneric("myGeneric"))
    myGeneric
    
    setGeneric("myGeneric", function(x) {
      standardGeneric("myGeneric")
    })
    myGeneric
    ```
    
1.  __<span style="color:red">Q</span>__: What happens if you define a method with different argument names to the generic?

    __<span style="color:green">A</span>__: It depends. Lets first create the object `hadley` of class "Person":
    
    ```{r, eval = TRUE}
    .Person <- setClass("Person", 
                        slots = c(
                          name = "character", 
                          age = "numeric"
                        )
                      )
    
    hadley <- .Person(name = "Hadley")
    hadley
    ```
    
    Now let us see, which arguments can be supplied to the `show()` generic
    
    ```{r, eval = TRUE}
    formals("show")
    ```
    
    Usually we would use this argument when defining a new method
    
    ```{r, eval = TRUE}
    setMethod("show", "Person", 
              function(object){
                cat(object@name, "creates hard exercises")
              })
    hadley
    ```
    
    When we supply another name, for example `x` instead of `object`, as a first element of our method, this becomes matched to the correct `object` argument and we get a warning.
    However, our method will work
    
    ```{r, eval = TRUE}
    setMethod("show", "Person", 
              function(x){
                cat(x@name, "creates hard exercises")
              })
    hadley
    ```
    
    If we add more arguments to our method than our generic can handle, we will get an error
    
    ```{r, eval = TRUE, error = TRUE}
    setMethod("show", "Person", 
              function(x, y){
                cat(x@name, "is", x@age, "years old")
              })
    ```
    
    However, if we do this with arguments added to the correctly written `object` argument, we will get the informative error message, that we could in general add other argument names for generics, which can take the `...` argument
    
    ```{r, eval = TRUE, error = TRUE}
    setMethod("show", "Person", 
              function(object, y){
                cat(object@name, "is", object@age, "years old")
              })
    ```

1.  __<span style="color:red">Q</span>__: What other ways can you find help for a method? Read `?"?"` and summarise the details.

    __<span style="color:orange">A</span>__: We can get
    
    * general documentation of the generic via `?genericName`
    * general documentation of the methods from a generic via `methods?genericName`
    * documentation of a specific method via `ClassName?methodName`
    
    Regarding the latter, we can also get help on a specific method via adding a `?` in front of a function call, like `?show(hadley)`.


## Method dispatch 

1.  __<span style="color:red">Q</span>__: Take the last example which shows multiple dispatch over two classes that use multiple inheritance. What happens if you define a method for all terminal classes? Why does method dispatch not save us much work here?

    __<span style="color:green">A</span>__: We will introduce ambiguity, since one class has distance 2 to all terminal nodes and the other 4 have distance 1 to two terminal nodes each. To resolve this ambiguity we have to define 5 more methods, one per class combination.

## S4 and existing code

### Exercises

[S4-bioconductor]: http://www.bioconductor.org/help/course-materials/2010/AdvancedR/S4InBioconductor.pdf
[S4DA]: http://amzn.com/0387759352?tag=devtools-20
[SO-Morgan]: http://stackoverflow.com/search?tab=votes&q=user%3a547331%20%5bs4%5d%20is%3aanswe


# R6

## Classes and methods

1.  __<span style="color:red">Q</span>__: Can subclasses access private fields/methods from their parent? Perform
    an experiment to find out.
    
## Controlling access

1.  __<span style="color:red">Q</span>__: How would you define a write-only field?

# Expressions

## Abstract syntax trees

1.  __<span style="color:red">Q</span>__: Use `ast()` and experimentation to figure out the three arguments to an `if()` call. What would you call them? Which arguments are required and which are optional?
    
    __<span style="color:green">A</span>__: You can write an `if()` statement in several ways: with or without `else`, formatted or in one line and also in prefix notation. Here are several versions focussing on the possibility of leaving out curly brackets.
    
    ```{r}
    lobstr::ast(if (TRUE) {} else {})
    lobstr::ast(if (TRUE) 1 else 2)
    lobstr::ast(`if`(TRUE, 1, 2))
    ```
    
    One possible way of naming the arguments would be: condition (1), conclusion (2), alternative (3).
    
    The *condition* is always required. If the *condition* is `TRUE`, also the *conclusion* is required. If the *condition* is `FALSE` and `if()` is called in combination with `else()`, then also the *alternative* is required.
    
1.  __<span style="color:red">Q</span>__: What does the call tree of an `if` statement with multiple `else if` conditions look like? Why?

    __<span style="color:green">A</span>__: The ast of nested `else if` statements might look a bit confusing because it contains multiple brackets. However, we can see that in the `else` part of the *ast* just another expression is being evaluated, which happens to be an `if` statement and so forth.
    
    ```{r}
    lobstr::ast(
    if (FALSE) {
      1
    } else if (FALSE) {
      2
    } else if (TRUE) {
      3
    }
    )
    ```
    
    We can see the structure more clearly when we avoid the curly brackets through prefix notation.
    
    ```{r}
    lobstr::ast(`if`(FALSE, 1, `if`(FALSE, 2, `if`(TRUE, 3))))
    ```

1.  __<span style="color:red">Q</span>__: What are the arguments to the `for()` and `while()` calls? 

    __<span style="color:green">A</span>__: `for()` requires an *index* (called `var` in the docs), a *sequence* and an *expression*, for example
    
    ```{r}
    `for`(i, 1:3, {print(i)})
    ```
    
    `while()` requires a *condition* and an *expression*. Again, an example in prefix notation:
    
    ```{r}
    set.seed(123)
    `while`((i <- rnorm(1)) < 1, {print(i)})
    i
    ```
    
    Note that a minimal expression can consist of `{` only.
    
1.  __<span style="color:red">Q</span>__: Two arithmetic operators can be used in both prefix and infix style.
    What are they?
    
    __<span style="color:green">A</span>__: I am not sure how this is meant to be. Theoretically every arithmetic operator can be written in prefix notation via backticks. On the other hand, `+` and `-` seem to be the only ones, which can be written in infix notation without backticks.
    
    ```{r}
    +(x)
    -(x)
    ```
    
    However, when we look more closely, the call tree is not what we would expect from a prefix function
    
    ```{r}
    lobstr::ast(+ (x))  
    lobstr::ast(- (x))  
    ```
    
    So maybe it is meant to look like this...
    
    ```{r}
    lobstr::ast(+ x)
    lobstr::ast(- x)
    ```
    
    Of course also this doesn't make too much sense, since in `?Syntax` one can read, that R clearly differentiates between unary and binary `+` and `-` operators and a unary operator is not really what we mean, when we speak about infix operators.
    
    However, if we don't differentiate in this way, this is probably the solution, since it's obviously also an infix function:
    
    ```{r}
    lobstr::ast(x + y)
    lobstr::ast(x - y)
    ```

## R's grammar

1.  __<span style="color:red">Q</span>__: R uses parentheses in two slightly different ways as illustrated by these two calls:

    ```{r, eval = FALSE}
    f((1))
    `(`(1 + 1)
    ```
    
    Compare and contrast the two uses by referencing the AST.
    
    __<span style="color:green">A</span>__: The trick with these examples lies in the fact, that `(` can represent a primitive function but also be a part of R's general prefix function syntax.
    
    So in the AST of the first example, we will not see the outer `(`, which belongs to `f()` and is therefore not shown in the syntax, while the inner `(` is treated as a function (symbol):
    
    ```{r}
    lobstr::ast(f((1)))
    ```
    
    In the second example, we can see that the outer `(` is treated as a function and the inner `(` belongs to its syntax:
    
    ```{r}
    lobstr::ast(`(`(1 + 1))
    ```
    
    For the sake of clarity, let's also create a third example, where none of the `(` is part of another functions syntax:
    
    ```{r}
    lobstr::ast(((1 + 1)))
    ```
    
1.  __<span style="color:red">Q</span>__: `=` can also be used in two ways. Construct a simple example that shows both uses.
    
    __<span style="color:green">A</span>__: I was not exactly aware of a similar case with multiple syntactical meanings for the `=` symbol, but one can get there somehow. `=` is used as an operator for assignment. It is also part of the logical operators `==`, `>=`, `<=`, `!=` and is also used within functions to assign parameters or the definition of default settings.
    
    The question probably aims at the difference of global assignment and parameter definition within functions.
    
    So when we play with `ast()`, we can directly see that the following is not possible
    
    ```{r, error = TRUE}
    lobstr::ast(a = 1)
    ```
    
    We get an error, because `a = ` makes R looking for an argument called `a`. Since `x` is the only argument of `lobstr::ast()`, we get an error.
    
    When we build our workaround for the problem, the solution to the question becomes obvious.
    
    Instead `a = 1`, we pass the expression via brackets to `ast()`. Once via matching by position and once via matching by name
    
    ```{r}
    lobstr::ast((a = 1))
    lobstr::ast(x = (a = 1))
    ```
    
    The second way is more explicit, but both return the same syntax tree. When wee ignore the `brackets` and compare the trees, we can finally see from the second tree, that the first `=` is just part of the syntax and the second one is for the usage of assignment.

1.  __<span style="color:red">Q</span>__: What does `!1 + !1` return? Why?

    __<span style="color:green">A</span>__: The first answer is quite simple
    
    ```{r}
    !1 + !1
    ```
    
    To answer the "Why", we have a look at the syntax tree first
    
    ```{r}
    lobstr::ast(!1 + !1)
    ```
    
    So first, the second `!1` becomes evaluated, which results in `FALSE`, because in R every non 0 numeric, becomes coerced to `TRUE`, when a logical operator is applied on it.
    
    Next `1 + FALSE` is evaluated to `1`, since `FALSE` is coerced to `0`.
    
    Finally `!1` is evaluated to `FALSE`, because it is the opposite of `TRUE`, which is what `1` becomes coerced to.
    
    However, note that if `!` had a higher precedence, the result would get `FALSE + FALSE` as intermediate result, which would be evalutated (again involving coercion) to `0`.

1.  __<span style="color:red">Q</span>__: Why does `x1 <- x2 <- x3 <- 0` work? There are two reasons.

    __<span style="color:orange">A</span>__: One reason is that `<-` is right-associative.

1.  __<span style="color:red">Q</span>__: Compare `x + y %+% z` to `x ^ y %+% z`. What does that tell you about the precedence of custom infix functions?

    __<span style="color:green">A</span>__: Comparison of the syntax trees:
    
    ```{r}
    # for ast(x + y %+% z)
    # y %+% z will be calculated first and the result will be added to x
    lobstr::ast(x + y %+% z)
    
    # for ast(x ^ y %+% z) 
    # x ^ y will be calculated first, and the result will be used as 
    # first argument of %+%()
    lobstr::ast(x ^ y %+% z)
    ```
    
    So we can conclude that custom infix functions must have a precedence between addition and exponentiation. The general precedence rules can be found for example [here](https://cran.r-project.org/doc/manuals/r-release/R-lang.html).

## Data structures

1.  __<span style="color:red">Q</span>__: Which two of the six types of atomic vector can't appear in an expression? 
    Why? Why can't you create an expression that contains an atomic vector of 
    length greater than one? 
    
    __<span style="color:green">A</span>__: It is not possible to create an expression that evaluates to an atomic of length greater than one without using a function (i.e. the `c()` function). But expressions that include a function would be calls.
    
    Let us illustrate this observation via the following example:
    
    ```{r}
    is.atomic(quote(1))       # atomic
    is.atomic(quote(c(1,1)))  # not an atomic (it would just evaluate to an atomic).
    is.call(quote(c(1,1)))    # still a call! (so at least a valid expression).
    ```
    <!-- HB: a little more explanation would be nice, I think. -->
    
    Two of the six atomic vector types of R do not work with expressions, the first one being raws. We assume, that raws may only be constructed through using `as.raw()`, but this function would then creating another call in the AST.
    
    For similar reasons complex numbers also won't work:
    
    ```{r}
    (function(x){is.atomic(x) & length(x) == 1})(quote(1 + 1.5i))
    
    # however, imaginary parts of complex numbers work:
    lobstr::ast(1i)
    ```
    <!-- HB: don't fully understand the first line of code in the above code-chunk -->
    
1.  __<span style="color:red">Q</span>__: How is `rlang::maybe_missing()` implemented? Why
does it work?

    __<span style="color:green">A</span>__: Let us take a look at the functions source code to see what's going on
    
    ```{r, eval = FALSE}
    lang::maybe_missing
    function (x) 
      {
      # is_missing checks if one of the following is TRUE
      # 1. check via substitute if typeof(x) is symbol and missing(x) is TRUE
      # 2. check if x identical to missing_arg()
      if (is_missing(x)) {
        missing_arg()  # returns missing argument
                       # implemented in lower level code -> .Call())
      }
      else {
        x  # when it's not missing, x is simply returned
      }
    }
    <bytecode: 0x00000000195ed740>
    <environment: namespace:rlang>
    ```
    <!-- HB: I think, I would try to split the explanation into two parts. One Overfiew with comments in the functions source code and then some prose summarising what's going on at a little higher level. Why does it work?-->    
    
    First it is checked if the argument is missing. If so, the missing arg is returned, otherwise the argument (`x`) itsself is returned.
    

1.  __<span style="color:red">Q</span>__: `rlang::call_standardise()` doesn't work so well for the following calls.
    Why? What makes `mean()` special?

    ```{r}
    call_standardise(quote(mean(1:10, na.rm = TRUE)))
    call_standardise(quote(mean(n = T, 1:10)))
    call_standardise(quote(mean(x = 1:10, , TRUE)))
    ```
    
    __<span style="color:green">A</span>__: The reason for this unexpected behaviour lies in the fact that `mean()` uses S3 dispatch (i.e., `UseMethod`) and therefore does not store its formals on `mean()`, but rather on `mean.default()`. `rlang::call_standardise()` can do much better when the S3 dispatch is explicit.
    
    ```{r}
    call_standardise(quote(mean.default(1:10, na.rm = TRUE)))
    call_standardise(quote(mean.default(n = T, 1:10)))
    call_standardise(quote(mean.default(x = 1:10, , TRUE)))
    ```

1.  __<span style="color:red">Q</span>__: Why does this code not make sense?

    ```{r, eval = FALSE}
    x <- expr(foo(x = 1))
    names(x) <- c("x", "")
    ```
    
    __<span style="color:green">A</span>__: As stated in the book
    
    > The first element of a call is always the function that gets called.
    
    We can just look what will happen
    
    ```{r}
    x <- rlang::expr(foo(x = 1))
    x
    
    names(x) <- c("x", "")
    x
    
    names(x) <- c("", "x")
    x
    ```
    
    So giving the first element a name just adds useless metadata.

1.  __<span style="color:red">Q</span>__: Construct the expression `if(x > 1) "a" else "b"` using multiple calls to `lang()`. How does the structure code reflect the structure of the AST?

    __<span style="color:green">A</span>__: Similar to the prefix version we get
    
    ```{r}
    rlang::lang("if", rlang::expr(x > 1), "a", "b")
    ```
    
    When we reed the AST from left to right, we get the same structure:
    Function to evaluate, expression, which is another function and becomes evaluated first and two constants which will be evaluated next
    
    ```{r}
    lobstr::ast(`if`(x > 1, "a", "b"))
    ```

## Parsing and deparsing

1.  __<span style="color:red">Q</span>__: What happens if you attempt to parse an invalid expression? e.g. `"a +"` or `"f())"`.

    __<span style="color:green">A</span>__: We get an error from the underlying `parse` function
    
    ```{r, error = TRUE}
    rlang::parse_expr("a +")
    rlang::parse_expr("f())")
    
    parse(text = "a +")
    parse(text = "f())")
    ```

1.  __<span style="color:red">Q</span>__: `deparse()` produces vectors when the input is long. For example, the following call produces a vector of length two:

    ```{r, eval = TRUE}
    expr <- rlang::expr(g(a + b + c + d + e + f + g + h + i + j + k + l + m +
      n + o + p + q + r + s + t + u + v + w + x + y + z))
    
    deparse(expr)
    ```

    What do `expr_text()`, `expr_name()`, and `expr_label()` do with this input?
    
    __<span style="color:green">A</span>__: 
    
    * `expr_text()` pastes the output string into one and inserts `\n` (new line identifiers) as separators
    
    ```{r}
    cat(rlang::expr_text(expr)) # cat is used for printing with linebreak
    ```
    
    * `expr_name()` recreates the call into the form f(...) and deparses this expression into a string
    
    ```{r}
    rlang::expr_name(expr)
    ```
    
    * `expr_label()` does the same as `expr_name()`, but surrounds the output also with backticks
    
    ```{r}
    rlang::expr_label(expr)
    ```

## Case study: Walking the AST with recursive functions {#ast-funs}

1.  __<span style="color:red">Q</span>__: `logical_abbr()` returns `TRUE` for `T(1, 2, 3)`. How could you modify `logical_abbr_rec()` so that it ignores function calls that use `T` or `F`?

    __<span style="color:green">A</span>__: We can apply a similar logic as in the multiple assignment example from the textbook and just treat this case as a special case handled within a sub function called `find_T_call()` which finds `T()` calls and "bounces them out":
    
    ```{r, include = FALSE}
    library(lobstr)
    library(rlang)
    
    expr_type <- function(x) {
      if (rlang::is_syntactic_literal(x)) {
      "constant"
      } else if (is.symbol(x)) {
      "symbol"
      } else if (is.call(x)) {
      "call"
      } else if (is.pairlist(x)) {
      "pairlist"
      } else {
      typeof(x)
      }
    }
  
    switch_expr <- function(x, ...) {
      switch(expr_type(x),
      ...,
      stop("Don't know how to handle type ", typeof(x), call. = FALSE))
    }
    ```
    
    ```{r}
    find_T_call <- function(x) {
      if (is_call(x, "T")) {
      x <- as.list(x)[-1]
      purrr::some(x, logical_abbr_rec)
      } else {
      purrr::some(x, logical_abbr_rec)
      }
    }
    
    logical_abbr_rec <- function(x) {
      switch_expr(
      x,
      # Base cases
      constant = FALSE,
      symbol = as_string(x) %in% c("F", "T"),
      
      # Recursive cases
      pairlist = purrr::some(x, logical_abbr_rec),
      call = find_T_call(x)
      )
    }
    
    logical_abbr <- function(x) {
      logical_abbr_rec(enexpr(x))
    }
    ```
    
    Now lets test our new `logical_abbr()` function:
    
    ```{r}
    logical_abbr(T(1, 2, 3))
    logical_abbr(T(T, T(3, 4)))
    logical_abbr(T(T))
    logical_abbr(T())
    logical_abbr()
    logical_abbr(c(T, T, T))
    ```

1.  __<span style="color:red">Q</span>__: `logical_abbr()` works with expressions. It currently fails when you give it a function. Why not? How could you modify `logical_abbr()` to make it work? What components of a function will you need to recurse over?

    ```{r, eval = FALSE}
    f <- function(x = TRUE) {
      g(x + T)
    }
    logical_abbr(!!f)
    ```
    
    __<span style="color:green">A</span>__: It currently fails, because `"closure"` is not handled within `switch_expr()` within `logical_abbr_rec()`. If we wanted to make it work, we must open a case there and write a function to inspect the formals and the body of the input function.

1.  __<span style="color:red">Q</span>__: Modify find assignment to also detect assignment using replacement functions, i.e. `names(x) <- y`.

    __<span style="color:green">A</span>__: Let`s see what the AST of such an assignment looks like:
    
    ```{r}
    ast(names(x) <- x)
    ```

    So we need to catch the case where the first two elements are both calls. Further the first call is identical to `<-` and we must return only the second call to see which objects got new values assigned.
    
    This is why we add the following block Within another `else` statement in `find_assign_call()`:
    
    ```{r, eval = FALSE}
    if (is_call(x, "<-") && is_call(x[[2]])) {
      lhs <- expr_text(x[[2]])
      children <- as.list(x)[-1]
    }
    ```
      
    Let us finish with the whole code including some tests for our new function:
    
    ```{r}
    flat_map_chr <- function(.x, .f, ...) {
      purrr::flatten_chr(purrr::map(.x, .f, ...))
    }
    
    find_assign <- function(x) unique(find_assign_rec(enexpr(x)))
    
    find_assign_call <- function(x) {
      if (is_call(x, "<-") && is_symbol(x[[2]])) {
        lhs <- as_string(x[[2]])
        children <- as.list(x)[-1]
      } else {
      if (is_call(x, "<-") && is_call(x[[2]])) {
        lhs <- expr_text(x[[2]])
        children <- as.list(x)[-1]
      } else {
        lhs <- character()
        children <- as.list(x)
      }}
      
      c(lhs, flat_map_chr(children, find_assign_rec))
    }
    
    find_assign_rec <- function(x) {
      switch_expr(
        x,
        # Base cases
        constant = ,symbol = character(),
        # Recursive cases
        pairlist = flat_map_chr(x, find_assign_rec),
        call = find_assign_call(x)
      )
    }
    
    find_assign(x <- y)
    find_assign(names(x))
    find_assign(names(x) <- y)
    find_assign(names(x(y)) <- y)
    find_assign(names(x(y)) <- y <- z)
    ```
  
1.  __<span style="color:red">Q</span>__: Write a function that extracts all calls to a specified function.

    __<span style="color:green">A</span>__: We just need to delete the former added else statement and check for a call (not necessarily `<-`) within the first `if()` in `find_assign_call()`. We save a call when we found one and return it later as part of our character output. Everything else stays the same:

    ```{r}
    find_assign_call <- function(x) {
      if (is_call(x)) {
        lhs <- expr_text(x)
        children <- as.list(x)[-1]
        } else {
          lhs <- character()
          children <- as.list(x)
        }
      
      c(lhs, flat_map_chr(children, find_assign_rec))
    }
    
    find_assign_rec <- function(x) {
      switch_expr(x,
                  # Base cases
                  constant = ,
                  symbol = character(),
                  
                  # Recursive cases
                  pairlist = flat_map_chr(x, find_assign_rec),
                  call = find_assign_call(x)
      )
    }
    
    find_assign(x <- y)
    find_assign(names(x(y)) <- y <- z)
    find_assign(mean(sum(1:3)))
    ```

# Quasiquotation

## Motivation

1.  __<span style="color:red">Q</span>__: For each function in the following base R code, identify which arguments are quoted and which are evaluated.

    ```{r, eval = FALSE}
    library(MASS)

    mtcars2 <- subset(mtcars, cyl == 4)

    with(mtcars2, sum(vs))
    sum(mtcars2$am)

    rm(mtcars2)
    ```
    
    __<span style="color:green">A</span>__: 
    
    ```{r, eval = FALSE}
    library(MASS)  # MASS -> quoted
    # library also accepts "MASS", which would be evaluated
    
    mtcars2 <- subset(mtcars, cyl == 4)  # mtcars -> evaluated
                                         # cyl    -> quoted
    with(mtcars2, sum(vs))  # mtcars2 -> evaluated
                            # sum(vs) -> quoted
    sum(mtcars2$am)  # matcars$am -> evaluated
                     # am -> quoted (via `$`)
    
    rm(mtcars2)  # mtcars2 -> quoted
```

Some of the arguments (`mtcars` or `mtcars2`) are objects, which can be found in the global environment. When you type them into the console, the object will be returned. Others such as `cyl`, `sum(vs)` or `am` will need to be evaluated within a certain environment. That's why they are quoted.

<!-- TODO: improve explanation, escpecially the last part. -->

1.  __<span style="color:red">Q</span>__: For each function in the following tidyverse code, identify which arguments are quoted and which are evaluated.

    ```{r, eval = FALSE}
    library(dplyr)
    library(ggplot2)

    by_cyl <- mtcars %>%
      group_by(cyl) %>%
      summarise(mean = mean(mpg))

    ggplot(by_cyl, aes(cyl, mean)) + geom_point()
    ```

    __<span style="color:green">A</span>__:
    
    ```{r, eval = FALSE}
    library(dplyr) # quoted
    library(ggplot2) # quoted
    
    by_cyl <- mtcars %>% # evaluated
      group_by(cyl) %>% # quoted
      summarise(mean = mean(mpg)) #quoted (`mean`, `mean()` and `mpg`)
    
    ggplot(by_cyl, # evaluated
           aes(cyl, mean)) + #evaluated (cyl and mean are quoted via aes)
      geom_point() 
    ```

## Quotation

1.  __<span style="color:red">Q</span>__: What happens if you try and use `enexpr()` with an expression?
    What happens if you try and use `enexpr()` with a missing argument?
    
    __<span style="color:green">A</span>__: In the first case we'll get an error:
    
    ```{r, error = TRUE}
    on_expr <- function(x) {enexpr(expr(x))}
    on_expr(x + y)
    ```
    
    In the second case a missing argument is returned:
    
    ```{r}
    on_missing <- function(x) {enexpr(x)}
    on_missing()
    is_missing(on_missing())
    ```

1.  __<span style="color:red">Q</span>__: Compare and contrast the following two functions. Can you predict the
    ouput before running them?

    ```{r, result = FALSE}
    f1 <- function(x, y) {
      exprs(x = x, y = y)
    }
    f2 <- function(x, y) {
      enexprs(x = x, y = y)
    }
    f1(a + b, c + d)
    f2(a + b, c + d)
    ```
    
    __<span style="color:green">A</span>__: Both return a named list of expressions. `f1()` will return the arguments supplied to `exprs()` within the body of `f1()`. `f2()` will return the arguments suppleid to `f2()`.
    
1.  __<span style="color:red">Q</span>__: How are `exprs(a)` and `exprs(a = )` different? Think about both the input and the output.
    
    __<span style="color:green">A</span>__: In `exprs(a)` the input of the first unnamed argument is the symbol `a`. So the output is an unnamed list with the first element containing the symbol `a`. In `exprs(a = )` the first argument is named `a` and missing. So the output is a named list with the first element named `a` and containing the missing argument.

1.  __<span style="color:red">Q</span>__: What does the following command return? What information is lost? Why?

    ```{r, eval = FALSE}
    expr({
      x +              y # comment  
    })
    ```

    __<span style="color:green">A</span>__: We get the expression `{x + y}`. Whitespaces and comments are lost, because R`s parsing ignores them. However, you can get the source information from the attributes of the expression:
    
    ```{r}
    attributes(expr({
      x +              y # comment  
    }))
    ```

1.  __<span style="color:red">Q</span>__: The documentation for `substitute()` says:

    > Substitution takes place by examining each component of the parse tree 
    > as follows: If it is not a bound symbol in env, it is unchanged. If it
    > is a promise object, i.e., a formal argument to a function or explicitly 
    created using delayedAssign(), the expression slot of the promise replaces 
    > the symbol. If it is an ordinary variable, its value is substituted, 
    > unless env is .GlobalEnv in which case the symbol is left unchanged.
    
    Create four examples that illustrate each of the different cases.

1.  __<span style="color:red">Q</span>__: Why does `as.Date.default()` use `substitute()` and `deparse()`?
    Why does `pairwise.t.test()` use them? Read the source code.

1.  __<span style="color:red">Q</span>__: `pairwise.t.test()` assumes that `deparse()` always returns a length one 
    character vector. Can you construct an input that violates this expectation? 
    What happens?

## Unquotation

1.  __<span style="color:red">Q</span>__: Given the following components:

    ```{r}
    xy <- expr(x + y)
    xz <- expr(x + z)
    yz <- expr(y + z)
    abc <- exprs(a, b, c)
    ```
    
    Use quasiquotation to construct the following calls:
    
    ```{r, eval = FALSE}
    (x + y) / (y + z)
    -(x + z) ^ (y + z)
    (x + y) + (y + z) - (x + y)
    atan2(x + y, y + z)
    sum(x + y, x + y, y + z)
    sum(a, b, c)
    mean(c(a, b, c), na.rm = TRUE)
    foo(a = x + y, b = y + z)
    ```
    
    __<span style="color:green">A</span>__: 
    
    ```{r}
    #1  (x + y) / (y + z)
    expr(!!xy / !!yz)
    #2  -(x + z) ^ (y + z)
    expr(-(!!xz)^(!!yz))
    #3  (x + y) + (y + z) - (x + y)
    expr(!!xy + !!yz - !!xz)
    #4  atan2(x + y, y + z)
    expr(atan2(!!xy, !!yz))
    #5  sum(x + y, x + y, y + z)
    expr(sum(!!xy, !!xy, !!yz))
    #6  sum(a, b, c)
    expr(sum(!!!abc))
    #7  mean(c(a, b, c), na.rm = TRUE)
    expr(mean(!!!abc, na.rm = TRUE))
    #8  foo(a = x + y, b = y + z)
    expr(foo(a = xy, b = yz))
    ```

1.  __<span style="color:red">Q</span>__: Explain why both `!0 + !0` and `!1 + !1` return `FALSE` while
    `!0 + !1` returns `TRUE`.
    
    __<span style="color:green">A</span>__: To answer this question we look at the AST of the first example:
    
    ```{r}
    ast(!0 + !0)
    ```
    
    As the coercion rules are the same in all examples, we can use the precedence order (right to left) to explain all three examples:
    
    * `!0 + !0`:  
      So the second zero gets coerced to `FALSE` and `!FALSE` becomes `TRUE`.  
      `0 + TRUE` gets coerced to 1.  
      `!1` becomes `!TRUE` which is `FALSE`  
    * `!1 + !1`:  
      So `!1` is `FALSE`.  
      `1 + FALSE` is `1`.  
      `!1` is `!TRUE` so `FALSE`.  
    * `!0 + !1`:  
      `!1` is `FALSE`.  
      `0 + FALSE` is `0`.  
      `!0` is `TRUE`.  

1.  __<span style="color:red">Q</span>__: Base functions `match.fun()`, `page()`, and `ls()` all try to
    automatically determine whether you want standard or non-standard
    evaluation. Each uses a different approach. Figure out the essence
    of each approach by reading the source code, then compare and contrast
    the techniques.

1.  __<span style="color:red">Q</span>__: The following two calls print the same, but are actually different:

    ```{r}
    (a <- expr(mean(1:10)))
    (b <- expr(mean(!!(1:10))))
    identical(a, b)
    ```

    What's the difference? Which one is more natural?
    
    __<span style="color:green">A</span>__: `call` evalulates its `...` arguments. So in the first call `1:10` will be evaluated to an integer (1, 2, 3, ..., 10) and in the second call `quote()` compensates the effect of the evaluation, so that `b`'s second element will be the expression `1:10` (which is again a call):
    
    ```{r, eval = TRUE}
    as.list(a)
    as.list(b)
    ```
    
    We can create an example, where we can see the consequences directly:
    
    ```{r, eval = TRUE}
    arg <- seq(10)
    call1 <- call("mean", arg)
    print(call1)
    call2 <- call("mean", quote(arg))
    print(call2)
    eval(call1)
    eval(call2)
    ```
    
    I would prefer the second version, since it behaves more like lazy evaluation. It's better to have call args depends on the calling environment rather than the enclosing environment,that's more similar to normal function behavior.

## Case studies {#quasi-case-studies}
    
1.  __<span style="color:red">Q</span>__: Implement `arrange_desc()`, a variant of `dplyr::arrange()` that sorts
    in descending order by default.
    
    __<span style="color:green">A</span>__: We just have to catch the `...` from `arrange()` as an expression and modify the expression to be wrapped inside `desc()`. Afterwards we evaluate this new code within a regular `arrange()` call:
    
    ```{r}
    library(dplyr)
    library(purrr)
    
    arrange_desc <- function(.data, ...){
      increasing <- enexprs(...)
      decreasing <- map(increasing, ~ expr(desc(!!.x)))
      
      arrange(.data, !!!decreasing)
    }
    ```
    
    Let's try it out
    
    ```{r}
    d <- data.frame(abc = letters[1:6],
                    id1 = 1:6,
                    id2 = rep(1:2, 3))
      
      # old behaviour
    d %>% arrange(id2, id1)
    
    # new descending behaviour
    d %>% arrange_desc(id2, id1)
    ```
  
1.  __<span style="color:red">Q</span>__: Implement `filter_or()`, a variant of `dplyr::filter()` that combines 
    multiple arguments using `|` instead of `&`.
    
    __<span style="color:green">A</span>__: This time we just need to collapse the `...` arguments with `|`. Therefore we can use `purrr::reduce()` and afterwards we just need to evaluate the new code within a regular filter call:
    
    ```{r}
    filter_or <- function(.data, ...){
      normal <- enexprs(...)
      
      normal_or <- reduce(normal, function(x, y) expr(!!x | !!y))
      
      filter(.data, !!!normal_or)
    }
    
    # and test it
    d <- data.frame(x = 1:6, y = 6:1)
    filter_or(d, x < 3, y < 3)
    ```

1.  __<span style="color:red">Q</span>__:Implement `partition_rows()` which, like `partition_cols()`, returns two
    data frames, one containing the selected rows, and the other containing
    the rows that weren't selected.
    
    __<span style="color:green">A</span>__: We just have to decide if we focus on integer subsetting via `dplyr::slice()` or logical subsetting via `dplyr::filter()`. The rest is straightforward. Since the implementations of both subsetting styles are completely equivalent we just choose one without any particular reason:
    
    ```{r}
    partition_rows <- function(.data, ...){
      included <- enexprs(...)
      excluded <- map(included, ~ expr(!(!!.x)))
      
      list(
        incl = filter(.data, !!!included),
        excl = filter(.data, !!!excluded)
      )
    }
    
    d <- data.frame(x = 1:6, y = 6:1)
    partition_rows(d, x <= 3)
    ```

1.  __<span style="color:red">Q</span>__:Add error handling to `slice()`. Give clear error messages if either
    `along` or `index` have invalid values (i.e. not numeric, not length 1,
    too small, or too big).

1.  __<span style="color:red">Q</span>__:Re-implement the Box-Cox transform defined below using unquoting and
    `new_function()`:

    ```{r}
    bc <- function(lambda) {
      if (lambda == 0) {
        function(x) log(x)
      } else {
        function(x) (x ^ lambda - 1) / lambda
      }
    }
    ```
    
    __<span style="color:green">A</span>__:
    
    ```{r}
    bc2 <- function(lambda){
      lambda <- enexpr(lambda)
      
      if(!!lambda == 0) {
        new_function(exprs(x = ), expr(log(x)))
        } else {
          new_function(exprs(x = ), expr((x^(!!lambda) - 1) / !!lambda))
        }
      }
    
    bc2(0)
    bc2(2)
    bc2(2)(2)
    ```

1.  __<span style="color:red">Q</span>__:Re-implement the simple `compose()` defined below using quasiquotation and 
    `new_function()`:
    
    ```{r}
    compose <- function(f, g) {
      function(...) f(g(...))
    }
    ```
    
    __<span style="color:green">A</span>__: The implementation is straight forward. However, it can become tough to handle all bracktes correct at the first try:
    
    ```{r}
    compose2 <- function(f, g){
      f <- enexpr(f)
      g <- enexpr(g)
      
      new_function(exprs(... = ), expr((!!f)((!!g)(...))))
    }
    
    compose(sin, cos)
    compose(sin, cos)(pi)
    compose2(sin, cos)
    compose2(sin, cos)(pi)
    ```

## Dot-dot-dot (`...`)

### Exercises

1.  __<span style="color:red">Q</span>__: Carefully read the source code for `interaction()`, `expand.grid()`, and 
    `par()`.  Compare and constract the techniques they use for switching 
    between dots and list behaviour.

1.  __<span style="color:red">Q</span>__: Explain the problem with this defintion of `set_attr()`
    
    ```{r, error = TRUE}
    set_attr <- function(x, ...) {
      attr <- rlang::list2(...)
      attributes(x) <- attr
      x
    }
    set_attr(1:10, x = 10)
    ```
    
    In this example we first learn that attributes must be named, as correctly given out by the error message. However, this behaviour mainly occures, because the first argument of `set_attr()` is named `x` as in the function call below. So the other argument in the `set_attr()` function call (`1:10`) is the only one, which is supplied as (unnamed) usage of the ellipsis. Therefore `set_attr()` tries to assign `1:10` as attribute to `x = 10` and the error occures.

The function becomes probably clearer and less error-prone when we name the first argument `.x` again. In this case `1:10` will get the (named) attribute `x = 10` assigned:

    ```{r}
    set_attr <- function(.x, ...) {
      attr <- rlang::list2(...)
      
      attributes(.x) <- attr
      .x
    }
    
    set_attr(1:10, x = 10)
    ```
    
# Evaluation

## Introduction

1.  __<span style="color:red">Q</span>__: Carefully read the documentation for `source()`. What environment does it
    use by default? What if you supply `local = TRUE`? How do you provide 
    a custom argument?
    
    __<span style="color:green">A</span>__:
    
    ```{r}
    tmp <- tempfile()
    writeLines("print(x)", tmp)  # create a temporary R-script

    x <- 2

    local({
      x <- 3
      source(tmp, local = FALSE)
    })    
    
    local({
      x <- 3
      source(tmp, local = TRUE)
    })
    
    env2 <- rlang::env(x = 4)
    local({
      x <- 3
      source(tmp, local = env2)
    })
    
    # Alternative:
    source_local <- function(file, local){
      local({
        x <- 3
        source(file, local = local)
      })      
    }
    
    source_local(tmp, FALSE)
    source_local(tmp, TRUE)
    source_local(tmp, env2)
    ```
    
    By default, the global environment is used, but also a local environment can be used. It is also possible to defince a specific environment by passing an environmen-object to `source`.
    
    [When would this be useful? usecases?]
    [should a better example, than 2,3,4 be used?]


1.  __<span style="color:red">Q</span>__: Predict the results of the following lines of code:

    ```{r, eval = FALSE}
    eval(quote(eval(quote(eval(quote(2 + 2))))))        # -> 4
    eval(eval(quote(eval(quote(eval(quote(2 + 2)))))))  # -> 4
    quote(eval(quote(eval(quote(eval(quote(2 + 2))))))) 
        # eval(quote(eval(quote(eval(quote(2 + 2))))))
    ```


    __<span style="color:green">A</span>__: An outside `quote()` always wins...

1.  __<span style="color:red">Q</span>__: Write an equivalent to `get()` using `sym()` and `eval_bare()`. Write an
    equivalent to `assign()` using `sym()`, `expr()`, and `eval_bare()`.
    (Don't worry about the multiple ways of choosing an environment that
    `get()` and `assign()` support; assume that the user supplies it 
    explicitly.)
    
    ```{r}
    # name is a string
    get2 <- function(name, env) {}
    assign2 <- function(name, value, env) {}
    ```
    
    __<span style="color:green">A</span>__:   

    ```{r}
    # name is a string
    get2 <- function(name, env) {}
    assign2 <- function(name, value, env) {}
    ```

1.  __<span style="color:red">Q</span>__: Modify `source2()` so it returns the result of _every_ expression,
    not just the last one. Can you eliminate the for loop?

1.  __<span style="color:red">Q</span>__: The code generated by `source2()` lacks source references. Read
    the source code for `sys.source()` and the help for `srcfilecopy()`,
    then modify `source2()` to preserve source references. You can
    test your code by sourcing a function that contains a comment. If
    successful, when you look at the function, you'll see the comment and
    not just the source code.

1.  __<span style="color:red">Q</span>__: The third argument in `subset()` allows you to select variables. It
    treats variable names as if they were positions. This allows you to do 
    things like `subset(mtcars, , -cyl)` to drop the cylinder variable, or
    `subset(mtcars, , disp:drat)` to select all the variables between `disp`
    and `drat`. How does this work? I've made this easier to understand by
    extracting it out into its own function that uses tidy evaluation.

    ```{r, eval = FALSE}
    select <- function(df, vars) {
      vars <- enexpr(vars)
      var_pos <- set_names(as.list(seq_along(df)), names(df))
      
      cols <- eval_tidy(vars, var_pos)
      df[, cols, drop = FALSE]
    }
    select(mtcars, -cyl)
    ```

1.  __<span style="color:red">Q</span>__: We can make `base::local()` slightly easier to understand by spreading
    out over multiple lines:

    ```{r}
    local3 <- function(expr, envir = new.env()) {
      call <- substitute(eval(quote(expr), envir))
      eval(call, envir = parent.frame())
    }
    ```
    
    Explain how `local()` works in words. (Hint: you might want to `print(call)`
    to help understand what `substitute()` is doing, and read the documentation
    to remind yourself what environment `new.env()` will inherit from.)
    
## Quosures

1.  __<span style="color:red">Q</span>__: Predict what evaluating each of the following quosures will return.

    ```{r}
    q1 <- new_quosure(expr(x), env(x = 1))
    q1
    
    q2 <- new_quosure(expr(x + !!q1), env(x = 10))
    q2
    
    q3 <- new_quosure(expr(x + !!q2), env(x = 100))
    q3
    ```
    
    __<span style="color:green">A</span>__: Each quosure will be evaluated in it's own environment. Hence we get:
    
    ```{r}
    eval_tidy(q1)
    eval_tidy(q2)
    eval_tidy(q3)
    ```

1.  __<span style="color:red">Q</span>__: Run this code in your head and predict what it will print. Confirm or 
    refute your prediction by running the code in R.

    ```{r, results = FALSE}
    f <- function(...) {
      x <- "f"
      g(f = x, ...)
    }
    g <- function(...) {
      x <- "g"
      h(g = x, ...)
    }
    h <- function(...) {
      enquos(...)
    }
    x <- "top"
    
    out <- f(top = x)
    out
    purrr::map_chr(out, eval_tidy)
    ```

## Tidy evaluation

1.  __<span style="color:red">Q</span>__: Improve `subset2()` to make it more like real subset function 
    (`subset.data.frame()`):
    
    * All drop rows where `subset` evaluates to `NA`
    * Give a clear error message if `subset` doesn't evalute to a logical vector
    * What happens if `subset` doesn't yield a logical vector with length
      equal to the number of rows in `data`? What do you think should happen?

1.  __<span style="color:red">Q</span>__: What happens if you use `expr()` instead of `enexpr()` inside of
    `subset2()`?

1.  __<span style="color:red">Q</span>__: Implement a form of `arrange()` where you can request a variable to 
    sorted in descending order using named arguments:
    
    ```{r, eval = FALSE}
    arrange(mtcars, cyl, desc = mpg, vs)
    ```
    
    (Hint:  The `descreasing` argument to `order()` will not help you. Instead,
    look at the definition of `dplyr::desc()`, and read the help for `xtfrm()`.)

1.  __<span style="color:red">Q</span>__: What does `transform()` do? Read the documentation. How does it work?
    Read the source code for `transform.data.frame()`. What does
    `substitute(list(...))` do?

1.  __<span style="color:red">Q</span>__: What does `with()` do? How does it work? Read the source code for
    `with.default()`. What does `within()` do? How does it work? Read the
    source code for `within.data.frame()`. Why is the code so much more
    complex than `with()`?

1.  __<span style="color:red">Q</span>__: Implement `with()` (code in `with.default()`).

1.  __<span style="color:red">Q</span>__: Implement a version of `within.data.frame()` that uses tidy evaluation.
    Read the documentation and make sure that you understand what `within()`
    does, then read the source code.

1.  __<span style="color:red">Q</span>__: Implement `transform()` (code in `transform.data.frame()`).  Extend it so that a
    variable can refer to the variables just defined.

## Case study: calling base NSE functions

### Exercises


## Capturing the current call {#capturing-call}

1.  __<span style="color:red">Q</span>__: Compare and contrast `update_model()` with `update.default()`.

1.  __<span style="color:red">Q</span>__: Why doesn't `write.csv(mtcars, "mtcars.csv", row = FALSE)` work?
    What property of argument matching has the original author forgotten?

1.  __<span style="color:red">Q</span>__: Rewrite `update.formula()` to use R code instead of C code.

1.  __<span style="color:red">Q</span>__: Sometimes it's necessary to uncover the function that called the
    function that called the current function (i.e., the grandparent, not
    the parent). How can you use `sys.call()` or `match.call()` to find
    this function?

# Homeless exercises

## Expressions (new)

1.  __<span style="color:red">Q</span>__: `base::alist()` is useful for creating pairlists to be used for function arguments:
    
    ```{r}
    foo <- function() {}
    formals(foo) <- alist(x = , y = 1)
    foo
    ```
    
    What makes `alist()` special compared to `list()`?
    
    __<span style="color:green">A</span>__: From `?alist`:
    
    > alist handles its arguments as if they described function arguments. So the values are not evaluated, and tagged arguments with no value are allowed whereas list simply ignores them. alist is most often used in conjunction with formals.

## Quasiquotation (new)

1.  __<span style="color:red">Q</span>__: Why does `as.Date.default()` use `substitute()` and `deparse()`? Why does `pairwise.t.test()` use them? Read the source code.

    __<span style="color:green">A</span>__: `as.Date.default()` uses them to convert unexpected input expressions (neither dates, nor `NAs`) into a character string and return it within an error message.
    
    `pairwise.t.test()` uses them to convert the names of its datainputs (response vector `x` and grouping factor `g`) into character strings to format these further into a part of the desired output.

1.  __<span style="color:red">Q</span>__: `pairwise.t.test()` assumes that `deparse()` always returns a length one character vector. Can you construct an input that violates this expectation? What happens? 

    __<span style="color:green">A</span>__: We can pass an expression to one of `pairwise.t.test()`'s data input arguments, which exceeds the default cutoff width in `deparse()`. The expression will be split into a character vector of length greater 1. The deparsed data inputs are directly pasted (read the source code!) with "and" as separator and the result is just used to be displayed in the output. Just the data.name output will change (it will include more than one "and").
    
    ```{r}
    d=1
    pairwise.t.test(2, d+d+d+d+d+d+d+d+d+d+d+d+d+d+d+d+d)
    ```
