```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
  cache = TRUE
)
```

# Function factories

## Prerequisites

```{r}
library(rlang)
```

## Factory fundamentals

1. __<span style="color:red">Q</span>__: Base R contains two function factories, `approxfun()` and `ecdf()`. 
    Read their documentation and experiment to figure out what the functions do and what they return.

   __<span style="color:green">A</span>__:

2. __<span style="color:red">Q</span>__: Create a function `pick()` that takes an index, `i`, as an argument and 
    returns a function with an argument `x` that subsets `x` with `i`.

    ```{r, eval = FALSE}
    pick(1)(x)
    # should be equivalent to
    x[[1]]
    
    lapply(mtcars, pick(5))
    # should be equivalent to
    lapply(mtcars, function(x) x[[5]])
    ```

   __<span style="color:green">A</span>__:
   
   ```{r}
   pick <- function(i) {
     function(x) x[[i]]
   }
   
   identical(x[[1]], pick(1)(x))
   identical(lapply(mtcars, pick(5)), lapply(mtcars, function(x) x[[5]]))
   ```

3. __<span style="color:red">Q</span>__: Create a function that creates functions that compute the i^th^ [central moment](http://en.wikipedia.org/wiki/Central_moment) of a numeric vector. You can test it by running the following code:

    ```{r, eval = FALSE}
    m1 <- moment(1)
    m2 <- moment(2)

    x <- runif(100)
    stopifnot(all.equal(m1(x), 0))
    stopifnot(all.equal(m2(x), var(x) * 99 / 100))
    ```

   __<span style="color:green">A</span>__:

4. __<span style="color:red">Q</span>__: What happens if you don't use a closure? Make predictions, then verify with the code below.

    ```{r}
    i <- 0
    new_counter2 <- function() {
      i <<- i + 1
      i
    }
    ```

   __<span style="color:green">A</span>__:

5. __<span style="color:red">Q</span>__: What happens if you use `<-` instead of `<<-`? Make predictions, then verify with the code below.

    ```{r}
    new_counter3 <- function() {
      i <- 0
      function() {
        i <- i + 1
        i
      }
    }
    ```

   __<span style="color:green">A</span>__:

## Graphical factories

1. __<span style="color:red">Q</span>__: Compare and contrast `ggplot2::label_bquote()` with `scales::number_format()`.

   __<span style="color:green">A</span>__:

## Statistical factories

1. __<span style="color:red">Q</span>__: In `boot_model()`, why don't I need to force the evaluation of `df` or `model`?

   __<span style="color:green">A</span>__:
    
2. __<span style="color:red">Q</span>__: Why might you formulate the Box-Cox transformation like this?

    ```{r}
    boxcox3 <- function(x) {
      function(lambda) {
        if (lambda == 0) {
          log(x)
        } else {
          (x ^ lambda - 1) / lambda
        }
      }  
    }
    ```

   __<span style="color:green">A</span>__:

3. __<span style="color:red">Q</span>__: Why don't you need to worry that `boot_permute()` stores a copy of the data inside the function that it generates?

   __<span style="color:green">A</span>__:

4. __<span style="color:red">Q</span>__: How much time does `ll_poisson2()` save compared to `ll_poisson1()`?
    Use `bench::mark()` to see how much faster the optimisation occurs.
    How does changing the length of `x` change the results?

   __<span style="color:green">A</span>__:

## Function factories + functionals

1. __<span style="color:red">Q</span>__: Which of the following commands is equivalent to `with(x, f(z))`?

   (a) `x$f(x$z)`.
   (b) `f(x$z)`.
   (c) `x$f(z)`.
   (d) `f(z)`.
   (e) It depends.

   __<span style="color:green">A</span>__:

2. __<span style="color:red">Q</span>__: Compare and contrast the effects of `env_bind()` vs. `attach()` for the following code.
   
    ```{r}
    funs <- list(
      mean = function(x) mean(x, na.rm = TRUE),
      sum = function(x) sum(x, na.rm = TRUE)
    )
    
    attach(funs)
    mean <- function(x) stop("Hi!")
    detach(funs)
    
    env_bind(globalenv(), !!!funs)
    mean <- function(x) stop("Hi!") 
    env_unbind(globalenv(), names(funs))
    ```

   __<span style="color:green">A</span>__:

## Old exercises

## Closures

1.  __<span style="color:red">Q</span>__: Why are functions created by other functions called closures?  
__<span style="color:green">A</span>__: As stated in the book:

    > because they enclose the environment of the parent function and can access all its variables.

2.  __<span style="color:red">Q</span>__: What does the following statistical function do? What would be a better 
    name for it? (The existing name is a bit of a hint.)

    ```{r}
    bc <- function(lambda) {
      if (lambda == 0) {
        function(x) log(x)
      } else {
        function(x) (x ^ lambda - 1) / lambda
      }
    }
    ```  
    
    __<span style="color:green">A</span>__: It is the logarithm, when lambda equals zero and `x ^ lambda - 1 / lambda` otherwise. A better name might be `box_cox_transformation` (one parametric), you can read about it (here)[https://en.wikipedia.org/wiki/Power_transform].
    
3.  __<span style="color:red">Q</span>__: What does `approxfun()` do? What does it return?  
__<span style="color:green">A</span>__: `approxfun` basically takes a combination of 2-dimensional data points + some extra specifications as arguments and returns a stepwise linear or constant interpolation function (defined on the range of given x-values, by default).

4.  __<span style="color:red">Q</span>__: What does `ecdf()` do? What does it return?  
__<span style="color:green">A</span>__: "ecdf" means empirical density function. For a numeric vector, `ecdf()` returns the appropriate density function (of class "ecdf", which is inheriting from class "stepfun"). You can describe it's behaviour in 2 steps. In the first part of it's body, the `(x,y)` pairs for the nodes of the density function are calculated. In the second part these pairs are given to `approxfun`.

5.  __<span style="color:red">Q</span>__: Create a function that creates functions that compute the ith 
    [central moment](http://en.wikipedia.org/wiki/Central_moment) of a numeric 
    vector. You can test it by running the following code:

    ```{r, eval = FALSE}
    m1 <- moment(1)
    m2 <- moment(2)

    x <- runif(100)
    stopifnot(all.equal(m1(x), 0))
    stopifnot(all.equal(m2(x), var(x) * 99 / 100))
    ```  
    
    __<span style="color:green">A</span>__: For a discrete formulation look [here](http://www.r-tutor.com/elementary-statistics/numerical-measures/moment)
    
    ```{r, eval = FALSE}
    moment <- function(i){
      function(x) sum((x - mean(x)) ^ i) / length(x)
      }
    ```

6.  __<span style="color:red">Q</span>__: Create a function `pick()` that takes an index, `i`, as an argument and 
    returns a function with an argument `x` that subsets `x` with `i`.

    ```{r, eval = FALSE}
    lapply(mtcars, pick(5))
    # should do the same as this
    lapply(mtcars, function(x) x[[5]])
    ```  
    
    __<span style="color:green">A</span>__: 
    
    ```{r, eval = FALSE}
    pick <- function(i){
      function(x) x[[i]]
      }
    
    stopifnot(identical(lapply(mtcars, pick(5)),
                        lapply(mtcars, function(x) x[[5]]))
              )
    ```    

## Case study: numerical integration

1.  __<span style="color:red">Q</span>__: Instead of creating individual functions (e.g., `midpoint()`, 
      `trapezoid()`, `simpson()`, etc.), we could store them in a list. If we 
    did that, how would that change the code? Can you create the list of 
    functions from a list of coefficients for the Newton-Cotes formulae?  
    __<span style="color:green">A</span>__: 

2.  __<span style="color:red">Q</span>__: The trade-off between integration rules is that more complex rules are 
    slower to compute, but need fewer pieces. For `sin()` in the range 
    [0, $\pi$], determine the number of pieces needed so that each rule will 
    be equally accurate. Illustrate your results with a graph. How do they
    change for different functions? `sin(1 / x^2)` is particularly challenging.  
    __<span style="color:green">A</span>__: 
